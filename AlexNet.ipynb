{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!time kg download # after configuring Kaggle CLI, this will download the dataset  \n",
    "!time unzip -q images_training_rev1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.34user 2.02system 0:10.39elapsed 99%CPU (0avgtext+0avgdata 3944maxresident)k\r\n",
      "0inputs+1883320outputs (0major+999minor)pagefaults 0swaps\r\n"
     ]
    }
   ],
   "source": [
    "!time unzip -q images_training_rev1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GalaxyID</th>\n",
       "      <th>Class1.1</th>\n",
       "      <th>Class1.2</th>\n",
       "      <th>Class1.3</th>\n",
       "      <th>Class2.1</th>\n",
       "      <th>Class2.2</th>\n",
       "      <th>Class3.1</th>\n",
       "      <th>Class3.2</th>\n",
       "      <th>Class4.1</th>\n",
       "      <th>Class4.2</th>\n",
       "      <th>...</th>\n",
       "      <th>Class9.3</th>\n",
       "      <th>Class10.1</th>\n",
       "      <th>Class10.2</th>\n",
       "      <th>Class10.3</th>\n",
       "      <th>Class11.1</th>\n",
       "      <th>Class11.2</th>\n",
       "      <th>Class11.3</th>\n",
       "      <th>Class11.4</th>\n",
       "      <th>Class11.5</th>\n",
       "      <th>Class11.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100008</td>\n",
       "      <td>0.383147</td>\n",
       "      <td>0.616853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616853</td>\n",
       "      <td>0.038452</td>\n",
       "      <td>0.578401</td>\n",
       "      <td>0.418398</td>\n",
       "      <td>0.198455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279952</td>\n",
       "      <td>0.138445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100023</td>\n",
       "      <td>0.327001</td>\n",
       "      <td>0.663777</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>0.031178</td>\n",
       "      <td>0.632599</td>\n",
       "      <td>0.467370</td>\n",
       "      <td>0.165229</td>\n",
       "      <td>0.591328</td>\n",
       "      <td>0.041271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131378</td>\n",
       "      <td>0.459950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.591328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100053</td>\n",
       "      <td>0.765717</td>\n",
       "      <td>0.177352</td>\n",
       "      <td>0.056931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100078</td>\n",
       "      <td>0.693377</td>\n",
       "      <td>0.238564</td>\n",
       "      <td>0.068059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238564</td>\n",
       "      <td>0.109493</td>\n",
       "      <td>0.129071</td>\n",
       "      <td>0.189098</td>\n",
       "      <td>0.049466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094549</td>\n",
       "      <td>0.189098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100090</td>\n",
       "      <td>0.933839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GalaxyID  Class1.1  Class1.2  Class1.3  Class2.1  Class2.2  Class3.1  \\\n",
       "0    100008  0.383147  0.616853  0.000000  0.000000  0.616853  0.038452   \n",
       "1    100023  0.327001  0.663777  0.009222  0.031178  0.632599  0.467370   \n",
       "2    100053  0.765717  0.177352  0.056931  0.000000  0.177352  0.000000   \n",
       "3    100078  0.693377  0.238564  0.068059  0.000000  0.238564  0.109493   \n",
       "4    100090  0.933839  0.000000  0.066161  0.000000  0.000000  0.000000   \n",
       "\n",
       "   Class3.2  Class4.1  Class4.2    ...      Class9.3  Class10.1  Class10.2  \\\n",
       "0  0.578401  0.418398  0.198455    ...      0.000000   0.279952   0.138445   \n",
       "1  0.165229  0.591328  0.041271    ...      0.018764   0.000000   0.131378   \n",
       "2  0.177352  0.000000  0.177352    ...      0.000000   0.000000   0.000000   \n",
       "3  0.129071  0.189098  0.049466    ...      0.000000   0.094549   0.000000   \n",
       "4  0.000000  0.000000  0.000000    ...      0.000000   0.000000   0.000000   \n",
       "\n",
       "   Class10.3  Class11.1  Class11.2  Class11.3  Class11.4  Class11.5  Class11.6  \n",
       "0   0.000000   0.000000   0.092886        0.0        0.0        0.0   0.325512  \n",
       "1   0.459950   0.000000   0.591328        0.0        0.0        0.0   0.000000  \n",
       "2   0.000000   0.000000   0.000000        0.0        0.0        0.0   0.000000  \n",
       "3   0.094549   0.189098   0.000000        0.0        0.0        0.0   0.000000  \n",
       "4   0.000000   0.000000   0.000000        0.0        0.0        0.0   0.000000  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "\n",
    "with zipfile.ZipFile('training_solutions_rev1.zip') as zfile:\n",
    "    with zfile.open('training_solutions_rev1.csv') as f:\n",
    "        df = pd.read_csv(f)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "img_names = df['GalaxyID'].astype('str') + '.jpg'\n",
    "labels = np.apply_along_axis(np.argmax, 1, df.iloc[:, 1:4].values)\n",
    "\n",
    "np.random.seed(42)\n",
    "train_val_test_split = np.random.choice(['train', 'val', 'test'], size=len(df), p=[0.6, 0.2, 0.2])\n",
    "\n",
    "old_path = 'images_training_rev1/'\n",
    "new_path = 'imgs/'\n",
    "\n",
    "for folder_path in ['train', 'val', 'test']:\n",
    "    for sub_path in set(labels):\n",
    "        new_dir = new_path + folder_path + '/' + str(sub_path)\n",
    "        if not os.path.isdir(new_dir):\n",
    "            print('Making new directory: {}'.format(new_dir))\n",
    "            os.makedirs(new_dir)\n",
    "\n",
    "for image_name, dataset, label in zip(img_names, train_val_test_split, labels):\n",
    "    try:\n",
    "        os.rename(old_path + image_name, new_path + dataset + '/' + str(label) + '/' + image_name)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36964 images belonging to 3 classes.\n",
      "Found 12383 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "\n",
    "train_batches = image.ImageDataGenerator().flow_from_directory(new_path + 'train/', target_size=(224, 224),\n",
    "            class_mode='categorical', shuffle=True, batch_size=64)\n",
    "val_batches = image.ImageDataGenerator().flow_from_directory(new_path + 'val/', target_size=(224, 224),\n",
    "            class_mode='categorical', shuffle=False, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1, input_shape=(3,224,224)))\n",
    "\n",
    "model.add(Convolution2D(96, 11, 11, activation='relu', subsample=(4, 4), border_mode='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), border_mode='same'))\n",
    "\n",
    "model.add(Convolution2D(256, 5, 5, activation='relu', border_mode='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), border_mode='same'))\n",
    "\n",
    "model.add(Convolution2D(384, 3, 3, activation='relu', border_mode='same'))\n",
    "model.add(Convolution2D(384, 3, 3, activation='relu', border_mode='same'))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', border_mode='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), border_mode='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096 // 10))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_1 (BatchNormal(None, 3, 224, 224)   6           batchnormalization_input_1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 96, 56, 56)    34944       batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNormal(None, 96, 56, 56)    192         convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 96, 28, 28)    0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 256, 28, 28)   614656      maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNormal(None, 256, 28, 28)   512         convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 256, 14, 14)   0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 384, 14, 14)   885120      maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 384, 14, 14)   1327488     convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 14, 14)   884992      convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNormal(None, 256, 14, 14)   512         convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 7, 7)     0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 12544)         0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 409)           5130905     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNormal(None, 409)           818         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 3)             1230        batchnormalization_5[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 8881375\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "36964/36964 [==============================] - 685s - loss: 0.6258 - acc: 0.7753 - val_loss: 0.4834 - val_acc: 0.7723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4ba536d650>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_batches, train_batches.N, nb_epoch=1, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2016/04/deep-learning-computer-vision-introduction-convolution-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" # for fast.ai\n",
    "Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Convolution2D(64,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Flatten(),\n",
    "            Dense(200, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AlexNet meant for 227 by 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/93 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36964 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|â–ˆâ–‰        | 18/93 [07:27<26:46, 21.41s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1a67f599ca84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0miPCA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iPCA.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/incremental_pca.pyc\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, check_input)\u001b[0m\n\u001b[1;32m    252\u001b[0m                           self.components_, X, mean_correction))\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd_flip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_based_decision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mexplained_variance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_total_samples\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/scipy/linalg/decomp_svd.pyc\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# perform decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     u, s, v, info = gesXd(a1, compute_uv=compute_uv, lwork=lwork,\n\u001b[0;32m--> 116\u001b[0;31m                           full_matrices=full_matrices, overwrite_a=overwrite_a)\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from tqdm import tqdm\n",
    "import cPickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "batch_size = 400\n",
    "train_batches = image.ImageDataGenerator().flow_from_directory('imgs/train/', target_size=(224, 224),\n",
    "            class_mode='categorical', shuffle=True, batch_size=batch_size)\n",
    "iPCA = IncrementalPCA(n_components=batch_size // 2)\n",
    "\n",
    "for i in tqdm(xrange(train_batches.N // batch_size + 1)):\n",
    "    images, classes = train_batches.next()\n",
    "    iPCA.partial_fit(images.reshape((len(images), -1)))\n",
    "    \n",
    "with open('iPCA.pkl', 'wb') as f:\n",
    "    pkl.dump(iPCA, f)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(iPCA.explained_variance_ratio_ * 100, label='PMF of Variance Explained')\n",
    "plt.plot(np.cumsum(iPCA.explained_variance_ratio_) * 100, label='CDF of Variance Exmplained')\n",
    "plt.legend()\n",
    "plt.xlabel('Components Sorted by Variance Explained')\n",
    "plt.ylabel('Percent of Variance Explained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36964 images belonging to 3 classes.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b21e64017c9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"from utils import *\\nimport cPickle as pkl\\nfrom tqdm import tqdm\\n\\n\\ndef transform_X_with_PCA(image_generator, iPCA): # generator must not be shuffled\\n    X_transformed = []\\n    y_labels = []\\n    for i in xrange(image_generator.N // image_generator.batch_size + 1):\\n        images, classes = image_generator.next()\\n        X_transformed.append(iPCA.transform(images.reshape((len(images), -1))))\\n        y_labels.append(classes)\\n    X_transformed = np.concatenate(X_transformed)\\n    y_labels = np.concatenate(y_labels)\\n    # need to truncate if over sampled by 1 iteration\\n    return X_transformed[:image_generator.N], y_labels[:image_generator.N]\\n\\n\\nwith open('iPCA.pkl', 'rb') as f:\\n    iPCA = pkl.load(f)\\n\\nnew_path = 'imgs/'\\nbatch_size = 300\\nfor folder in tqdm(['train', 'val', 'test']):\\n    # transforming images to lower dimensionality\\n    image_generator = image.ImageDataGenerator().flow_from_directory(new_path + folder, \\n            target_size=(224, 224),class_mode='categorical', shuffle=False, \\n            batch_size=batch_size)\\n    X_transformed, y_labels = transform_X_with_PCA(image_generator, iPCA)\\n    \\n    # performing sanity check to make sure image names and image data are aligned by index\\n    data_transformed = {'image_names': image_generator.filenames, 'X_transformed': \\n                    X_transformed, 'y_labels': np.argmax(y_labels, axis=1)}\\n    print('\\\\nData set: {}'.format(folder))\\n    print('All arrays have the same length: {}'.format(\\n            len(data_transformed['X_transformed']) == \\n                len(data_transformed['y_labels']) == \\n                len(data_transformed['image_names'])))\\n    class_labels = np.array([fname[0] for fname in data_transformed['image_names']])\\n    print('All image classes appear to match up: {}'.format(\\n            (data_transformed['y_labels'].astype('str') == class_labels).all()))\\n\\n    # save transformed vectors to disk\\n    with open(folder + '_transformed.pkl', 'wb') as f:\\n        pkl.dump(data_transformed, f)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mtransform_X_with_PCA\u001b[0;34m(image_generator, iPCA)\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/preprocessing/image.pyc\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrayscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_ordering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim_ordering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/preprocessing/image.pyc\u001b[0m in \u001b[0;36mrandom_transform\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mtransform_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_matrix_offset_center\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         x = apply_transform(x, transform_matrix, img_channel_index,\n\u001b[0;32m--> 362\u001b[0;31m                             fill_mode=self.fill_mode, cval=self.cval)\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_shift_range\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_channel_shift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_shift_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_channel_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/preprocessing/image.pyc\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(x, transform_matrix, channel_index, fill_mode, cval)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mfinal_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     channel_images = [ndi.interpolation.affine_transform(x_channel, final_affine_matrix,\n\u001b[0;32m--> 108\u001b[0;31m                       final_offset, order=0, mode=fill_mode, cval=cval) for x_channel in x]\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/scipy/ndimage/interpolation.pyc\u001b[0m in \u001b[0;36maffine_transform\u001b[0;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         _geometric_transform(filtered, None, None, matrix, offset,\n\u001b[0;32m--> 470\u001b[0;31m                              output, order, mode, cval, None, None)\n\u001b[0m\u001b[1;32m    471\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreturn_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/scipy/ndimage/interpolation.pyc\u001b[0m in \u001b[0;36m_geometric_transform\u001b[0;34m(input, mapping, coordinates, matrix, offset, output, order, mode, cval, extra_arguments, extra_keywords)\u001b[0m\n\u001b[1;32m    130\u001b[0m     _nd_image.geometric_transform(\n\u001b[1;32m    131\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         order, mode, cval, extra_arguments, extra_keywords)\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnative\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from utils import *\n",
    "import cPickle as pkl\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def transform_X_with_PCA(image_generator, iPCA): # generator must not be shuffled\n",
    "    X_transformed = []\n",
    "    y_labels = []\n",
    "    for i in xrange(image_generator.N // image_generator.batch_size + 1):\n",
    "        images, classes = image_generator.next()\n",
    "        X_transformed.append(iPCA.transform(images.reshape((len(images), -1))))\n",
    "        y_labels.append(classes)\n",
    "    X_transformed = np.concatenate(X_transformed)\n",
    "    y_labels = np.concatenate(y_labels)\n",
    "    # need to truncate if over sampled by 1 iteration\n",
    "    return X_transformed[:image_generator.N], y_labels[:image_generator.N]\n",
    "\n",
    "\n",
    "with open('iPCA.pkl', 'rb') as f:\n",
    "    iPCA = pkl.load(f)\n",
    "\n",
    "new_path = 'imgs/'\n",
    "batch_size = 300\n",
    "for folder in tqdm(['train', 'val', 'test']):\n",
    "    # transforming images to lower dimensionality\n",
    "    print('\\nData set: {}'.format(folder))\n",
    "    image_generator = image.ImageDataGenerator().flow_from_directory(new_path + folder, \n",
    "            target_size=(224, 224), class_mode='categorical', shuffle=False, \n",
    "            batch_size=batch_size)\n",
    "    X_transformed, y_labels = transform_X_with_PCA(image_generator, iPCA)\n",
    "    \n",
    "    data_transformed = {'image_names': image_generator.filenames, 'X_transformed': \n",
    "                    X_transformed, 'y_labels': np.argmax(y_labels, axis=1)}\n",
    "\n",
    "    # performing sanity check to make sure image names and image data are aligned by index\n",
    "    print('All arrays have the same length: {}'.format(\n",
    "            len(data_transformed['X_transformed']) == \n",
    "                len(data_transformed['y_labels']) == \n",
    "                len(data_transformed['image_names'])))\n",
    "    class_labels = np.array([fname[0] for fname in data_transformed['image_names']])\n",
    "    print('All image classes appear to match up: {}'.format(\n",
    "            (data_transformed['y_labels'].astype('str') == class_labels).all()))\n",
    "\n",
    "    # save transformed vectors to disk\n",
    "    with open(folder + '_transformed.pkl', 'wb') as f:\n",
    "        pkl.dump(data_transformed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 s, sys: 268 ms, total: 12.2 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import cPickle as pkl\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('train_transformed.pkl', 'rb') as f:\n",
    "    train_transformed = pkl.load(f)\n",
    "with open('val_transformed.pkl', 'rb') as f:\n",
    "    val_transformed = pkl.load(f)\n",
    "with open('test_transformed.pkl', 'rb') as f:\n",
    "    test_transformed = pkl.load(f)\n",
    "\n",
    "#X_transformed = np.concatenate([train_transformed['X_transformed'], val_transformed['X_transformed']])\n",
    "#y_labels = np.concatenate([train_transformed['y_labels'], val_transformed['y_labels']])\n",
    "\n",
    "X_transformed = train_transformed['X_transformed']\n",
    "y_labels = train_transformed['y_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 200), (3000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.array(xrange(len(X_transformed)))\n",
    "np.random.shuffle(mask)\n",
    "mask = mask[:3000]\n",
    "X_transformed = X_transformed[mask]\n",
    "y_labels = y_labels[mask]\n",
    "\n",
    "X_transformed.shape, y_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] n_estimators=50, max_depth=3 ....................................\n",
      "[CV] n_estimators=50, max_depth=3 ....................................\n",
      "[CV] n_estimators=50, max_depth=3 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... n_estimators=50, max_depth=3, total=   0.6s\n",
      "[CV] n_estimators=100, max_depth=3 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... n_estimators=50, max_depth=3, total=   0.6s\n",
      "[CV] n_estimators=100, max_depth=3 ...................................\n",
      "[CV] ..................... n_estimators=50, max_depth=3, total=   0.8s\n",
      "[CV] n_estimators=100, max_depth=3 ...................................\n",
      "[CV] .................... n_estimators=100, max_depth=3, total=   0.9s\n",
      "[CV] n_estimators=50, max_depth=4 ....................................\n",
      "[CV] .................... n_estimators=100, max_depth=3, total=   1.1s\n",
      "[CV] n_estimators=50, max_depth=4 ....................................\n",
      "[CV] .................... n_estimators=100, max_depth=3, total=   1.1s\n",
      "[CV] n_estimators=50, max_depth=4 ....................................\n",
      "[CV] ..................... n_estimators=50, max_depth=4, total=   0.6s\n",
      "[CV] n_estimators=100, max_depth=4 ...................................\n",
      "[CV] ..................... n_estimators=50, max_depth=4, total=   0.7s\n",
      "[CV] n_estimators=100, max_depth=4 ...................................\n",
      "[CV] ..................... n_estimators=50, max_depth=4, total=   0.7s\n",
      "[CV] n_estimators=100, max_depth=4 ...................................\n",
      "[CV] .................... n_estimators=100, max_depth=4, total=   1.0s\n",
      "[CV] .................... n_estimators=100, max_depth=4, total=   1.1s\n",
      "[CV] .................... n_estimators=100, max_depth=4, total=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done  12 out of  12 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.15 s, sys: 72 ms, total: 2.22 s\n",
      "Wall time: 5.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Grid Search over Random Forest Hyperparameters using Stratified K-Fold Cross Validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-2, oob_score=True, random_state=42)\n",
    "param_grid = {\n",
    "            \"n_estimators\": [50, 100], \n",
    "            'max_depth': range(3, 5)\n",
    "            }\n",
    "# 3 splits for faster training, there is sufficient data to prevent overfitting\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=kfold, n_jobs=-2, scoring='f1_weighted', verbose=2)\n",
    "grid_search.fit(X_transformed, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, \\\n",
    "    recall_score, f1_score, confusion_matrix, auc, roc_curve\n",
    "    \n",
    "    \n",
    "def print_metrics(y_actual, y_predict, average='weighted'):\n",
    "    \"\"\"Prints multiple metrics\"\"\"\n",
    "    print \"Accuracy:\", (y_predict == y_actual).mean()\n",
    "    print \"Precision:\", precision_score(y_actual, y_predict, average=average)\n",
    "    print \"Recall:\", recall_score(y_actual, y_predict, average=average)\n",
    "    print \"F1-score:\", f1_score(y_actual, y_predict, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 100, 'max_depth': 4}\n",
      "\n",
      "Accuracy: 0.776666666667\n",
      "Precision: 0.805067583218\n",
      "Recall: 0.776666666667\n",
      "F1-score: 0.763611355741\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparameters: {}\\n'.format(grid_search.best_params_))\n",
    "print_metrics(y_labels, grid_search.predict(X_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.701203262537\n",
      "Precision: 0.73086478903\n",
      "Recall: 0.701203262537\n",
      "F1-score: 0.676356139302\n"
     ]
    }
   ],
   "source": [
    "print_metrics(val_transformed['y_labels'], grid_search.predict(val_transformed['X_transformed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 711  590    0]\n",
      " [  77 1619    0]\n",
      " [   0    3    0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBGOMMYAFBGOMMY4FBGOMMQD8fxqBp3p2NhOEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8977406650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8977a791d0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8977af2790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(confusion_matrix(y_labels, grid_search.best_estimator_.predict(X_transformed)))\n",
    "plt.plot(grid_search.best_estimator_.feature_importances_, marker='.')\n",
    "plt.show()\n",
    "plt.plot(sorted(grid_search.best_estimator_.feature_importances_)[::-1], marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.696427111438\n",
      "Precision: 0.72422277394\n",
      "Recall: 0.696427111438\n",
      "F1-score: 0.67031959083\n"
     ]
    }
   ],
   "source": [
    "y_predictions = grid_search.predict(test_transformed['X_transformed'])\n",
    "print_metrics(test_transformed['y_labels'], y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Metrics on Training Set\"\n",
    "print_metrics(y_labels, grid_search.predict(X_transformed))\n",
    "\n",
    "print \"Metrics on Test Set\"\n",
    "y_predictions = grid_search.predict(test_transformed['X_transformed'])\n",
    "print_metrics(test_transformed['y_labels'], y_predictions)\n",
    "print confusion_matrix(test_transformed['y_labels'], y_predictions)\n",
    "plot_ROC(y_val, grid_search.predict_proba(test_transformed['X_transformed'])[:, 1])\n",
    "\n",
    "\n",
    "\n",
    "# For reading confusion matrix, get a nice plot\n",
    "#  [[TN FP]\n",
    "#   [TN TP]]\n",
    "\n",
    "# get the feature importance\n",
    "# check which hyperparameters were the besta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# glorot initialization?\n",
    "# sigmoid vs relu\n",
    "# increase dense neurons or more filters\n",
    "# learning rate\n",
    "# want to overfit; ideally should be more accurate than 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3648/3696 [============================>.] - ETA: 0s - loss: 0.9257 - acc: 0.5400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.py:1462: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3712/3696 [==============================] - 205s - loss: 0.9215 - acc: 0.5412 - val_loss: 0.7204 - val_acc: 0.5621\n",
      "CPU times: user 3min 24s, sys: 15.7 s, total: 3min 40s\n",
      "Wall time: 3min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "LeNet = get_LeNet_model()\n",
    "LeNet.optimizer.lr = 0.1\n",
    "LeNet.fit_generator(train_batches, train_batches.N // 10, nb_epoch=1, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3712/3696 [==============================] - 190s - loss: 0.7125 - acc: 0.5348 - val_loss: 0.6930 - val_acc: 0.5621\n",
      "CPU times: user 3min 21s, sys: 14.5 s, total: 3min 35s\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "LeNet.optimizer.lr = 0.1\n",
    "LeNet.fit_generator(train_batches, train_batches.N // 10, nb_epoch=1, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4187,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LeNet.predict(train_batches.next()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {},
  "nbpresent": {
   "slides": {
    "28b43202-5690-4169-9aca-6b9dabfeb3ec": {
     "id": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "prev": null,
     "regions": {
      "3bba644a-cf4d-4a49-9fbd-e2554428cf9f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f3d3a388-7e2a-4151-9b50-c20498fceacc",
        "part": "whole"
       },
       "id": "3bba644a-cf4d-4a49-9fbd-e2554428cf9f"
      }
     }
    },
    "8104def2-4b68-44a0-8f1b-b03bf3b2a079": {
     "id": "8104def2-4b68-44a0-8f1b-b03bf3b2a079",
     "prev": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "regions": {
      "7dded777-1ddf-4100-99ae-25cf1c15b575": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fe47bd48-3414-4657-92e7-8b8d6cb0df00",
        "part": "whole"
       },
       "id": "7dded777-1ddf-4100-99ae-25cf1c15b575"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
