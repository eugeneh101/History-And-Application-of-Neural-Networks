{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!time kg download # after configuring Kaggle CLI, this will download the dataset  \n",
    "!time unzip -q images_training_rev1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.34user 2.02system 0:10.39elapsed 99%CPU (0avgtext+0avgdata 3944maxresident)k\r\n",
      "0inputs+1883320outputs (0major+999minor)pagefaults 0swaps\r\n"
     ]
    }
   ],
   "source": [
    "!time unzip -q images_training_rev1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GalaxyID</th>\n",
       "      <th>Class1.1</th>\n",
       "      <th>Class1.2</th>\n",
       "      <th>Class1.3</th>\n",
       "      <th>Class2.1</th>\n",
       "      <th>Class2.2</th>\n",
       "      <th>Class3.1</th>\n",
       "      <th>Class3.2</th>\n",
       "      <th>Class4.1</th>\n",
       "      <th>Class4.2</th>\n",
       "      <th>...</th>\n",
       "      <th>Class9.3</th>\n",
       "      <th>Class10.1</th>\n",
       "      <th>Class10.2</th>\n",
       "      <th>Class10.3</th>\n",
       "      <th>Class11.1</th>\n",
       "      <th>Class11.2</th>\n",
       "      <th>Class11.3</th>\n",
       "      <th>Class11.4</th>\n",
       "      <th>Class11.5</th>\n",
       "      <th>Class11.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100008</td>\n",
       "      <td>0.383147</td>\n",
       "      <td>0.616853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616853</td>\n",
       "      <td>0.038452</td>\n",
       "      <td>0.578401</td>\n",
       "      <td>0.418398</td>\n",
       "      <td>0.198455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279952</td>\n",
       "      <td>0.138445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100023</td>\n",
       "      <td>0.327001</td>\n",
       "      <td>0.663777</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>0.031178</td>\n",
       "      <td>0.632599</td>\n",
       "      <td>0.467370</td>\n",
       "      <td>0.165229</td>\n",
       "      <td>0.591328</td>\n",
       "      <td>0.041271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131378</td>\n",
       "      <td>0.459950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.591328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100053</td>\n",
       "      <td>0.765717</td>\n",
       "      <td>0.177352</td>\n",
       "      <td>0.056931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100078</td>\n",
       "      <td>0.693377</td>\n",
       "      <td>0.238564</td>\n",
       "      <td>0.068059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238564</td>\n",
       "      <td>0.109493</td>\n",
       "      <td>0.129071</td>\n",
       "      <td>0.189098</td>\n",
       "      <td>0.049466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094549</td>\n",
       "      <td>0.189098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100090</td>\n",
       "      <td>0.933839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GalaxyID  Class1.1  Class1.2  Class1.3  Class2.1  Class2.2  Class3.1  \\\n",
       "0    100008  0.383147  0.616853  0.000000  0.000000  0.616853  0.038452   \n",
       "1    100023  0.327001  0.663777  0.009222  0.031178  0.632599  0.467370   \n",
       "2    100053  0.765717  0.177352  0.056931  0.000000  0.177352  0.000000   \n",
       "3    100078  0.693377  0.238564  0.068059  0.000000  0.238564  0.109493   \n",
       "4    100090  0.933839  0.000000  0.066161  0.000000  0.000000  0.000000   \n",
       "\n",
       "   Class3.2  Class4.1  Class4.2    ...      Class9.3  Class10.1  Class10.2  \\\n",
       "0  0.578401  0.418398  0.198455    ...      0.000000   0.279952   0.138445   \n",
       "1  0.165229  0.591328  0.041271    ...      0.018764   0.000000   0.131378   \n",
       "2  0.177352  0.000000  0.177352    ...      0.000000   0.000000   0.000000   \n",
       "3  0.129071  0.189098  0.049466    ...      0.000000   0.094549   0.000000   \n",
       "4  0.000000  0.000000  0.000000    ...      0.000000   0.000000   0.000000   \n",
       "\n",
       "   Class10.3  Class11.1  Class11.2  Class11.3  Class11.4  Class11.5  Class11.6  \n",
       "0   0.000000   0.000000   0.092886        0.0        0.0        0.0   0.325512  \n",
       "1   0.459950   0.000000   0.591328        0.0        0.0        0.0   0.000000  \n",
       "2   0.000000   0.000000   0.000000        0.0        0.0        0.0   0.000000  \n",
       "3   0.094549   0.189098   0.000000        0.0        0.0        0.0   0.000000  \n",
       "4   0.000000   0.000000   0.000000        0.0        0.0        0.0   0.000000  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "\n",
    "with zipfile.ZipFile('training_solutions_rev1.zip') as zfile:\n",
    "    with zfile.open('training_solutions_rev1.csv') as f:\n",
    "        df = pd.read_csv(f)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "img_names = df['GalaxyID'].astype('str') + '.jpg'\n",
    "labels = np.apply_along_axis(np.argmax, 1, df.iloc[:, 1:4].values)\n",
    "\n",
    "np.random.seed(42)\n",
    "train_val_test_split = np.random.choice(['train', 'val', 'test'], size=len(df), p=[0.6, 0.2, 0.2])\n",
    "\n",
    "old_path = 'images_training_rev1/'\n",
    "new_path = 'imgs/'\n",
    "\n",
    "for folder_path in ['train', 'val', 'test']:\n",
    "    for sub_path in set(labels):\n",
    "        new_dir = new_path + folder_path + '/' + str(sub_path)\n",
    "        if not os.path.isdir(new_dir):\n",
    "            print('Making new directory: {}'.format(new_dir))\n",
    "            os.makedirs(new_dir)\n",
    "\n",
    "for image_name, dataset, label in zip(img_names, train_val_test_split, labels):\n",
    "    try:\n",
    "        os.rename(old_path + image_name, new_path + dataset + '/' + str(label) + '/' + image_name)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36964 images belonging to 3 classes.\n",
      "Found 12383 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "\n",
    "train_batches = image.ImageDataGenerator().flow_from_directory(new_path + 'train/', target_size=(224, 224),\n",
    "            class_mode='categorical', shuffle=True, batch_size=64)\n",
    "val_batches = image.ImageDataGenerator().flow_from_directory(new_path + 'val/', target_size=(224, 224),\n",
    "            class_mode='categorical', shuffle=False, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(axis=1, input_shape=(3,224,224)))\n",
    "\n",
    "model.add(Convolution2D(96, 11, 11, activation='relu', subsample=(4, 4), border_mode='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), border_mode='same'))\n",
    "\n",
    "model.add(Convolution2D(256, 5, 5, activation='relu', border_mode='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), border_mode='same'))\n",
    "\n",
    "model.add(Convolution2D(384, 3, 3, activation='relu', border_mode='same'))\n",
    "model.add(Convolution2D(384, 3, 3, activation='relu', border_mode='same'))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', border_mode='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), border_mode='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096 // 10))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_1 (BatchNormal(None, 3, 224, 224)   6           batchnormalization_input_1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 96, 56, 56)    34944       batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNormal(None, 96, 56, 56)    192         convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 96, 28, 28)    0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 256, 28, 28)   614656      maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNormal(None, 256, 28, 28)   512         convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 256, 14, 14)   0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 384, 14, 14)   885120      maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 384, 14, 14)   1327488     convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 256, 14, 14)   884992      convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNormal(None, 256, 14, 14)   512         convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 256, 7, 7)     0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 12544)         0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 409)           5130905     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNormal(None, 409)           818         dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 3)             1230        batchnormalization_5[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 8881375\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "36964/36964 [==============================] - 685s - loss: 0.6258 - acc: 0.7753 - val_loss: 0.4834 - val_acc: 0.7723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4ba536d650>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_batches, train_batches.N, nb_epoch=1, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2016/04/deep-learning-computer-vision-introduction-convolution-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" # for fast.ai\n",
    "Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Convolution2D(64,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Flatten(),\n",
    "            Dense(200, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AlexNet meant for 227 by 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36964 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "new_path = 'imgs/'\n",
    "batch_size = 400\n",
    "\n",
    "train_batches = image.ImageDataGenerator().flow_from_directory(new_path + 'train/', target_size=(224, 224),\n",
    "            class_mode='categorical', shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 93/93 [34:17<00:00, 17.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53min 59s, sys: 2min 16s, total: 56min 16s\n",
      "Wall time: 34min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from tqdm import tqdm\n",
    "import cPickle as pkl\n",
    "\n",
    "iPCA = IncrementalPCA(n_components=batch_size // 2)\n",
    "\n",
    "for i in tqdm(xrange(train_batches.N // batch_size + 1)):\n",
    "    images, classes = train_batches.next()\n",
    "    iPCA.partial_fit(images.reshape((len(images), -1)))\n",
    "    \n",
    "with open('iPCA.pkl', 'wb') as f:\n",
    "    pkl.dump(iPCA, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56 ms, sys: 4 ms, total: 60 ms\n",
      "Wall time: 55.2 ms\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFACAYAAADu2N6nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84d0df8e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(iPCA.explained_variance_ratio_ * 100, label='PMF of Variance Explained')\n",
    "plt.plot(np.cumsum(iPCA.explained_variance_ratio_) * 100, label='CDF of Variance Exmplained')\n",
    "plt.legend()\n",
    "plt.xlabel('Components Sorted by Variance Explained')\n",
    "plt.ylabel('Percent of Variance Explained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-259def02b636>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"import cPickle as pkl\\nfrom tqdm import tqdm\\n\\n\\ndef transform_X_with_PCA(image_generator, iPCA): # generator must not be shuffled\\n    X_transformed = []\\n    y_labels = []\\n    for i in xrange(image_generator.N // image_generator.batch_size + 1):\\n        images, classes = image_generator.next()\\n        X_transformed.append(iPCA.transform(images.reshape((len(images), -1))))\\n        y_labels.append(classes)\\n    X_transformed = np.concatenate(X_transformed)\\n    y_labels = np.concatenate(y_labels)\\n    # need to truncate if over sampled by 1 iteration\\n    return X_transformed[:image_generator.N], y_labels[:image_generator.N]\\n\\n\\nwith open('iPCA.pkl', 'rb') as f:\\n    iPCA = pkl.load(f)\\n\\nfor folder in tqdm(['train', 'val', 'test']):\\n    # transforming images to lower dimensionality\\n    image_generator = image.ImageDataGenerator().flow_from_directory(new_path + folder, \\n            target_size=(224, 224),class_mode='categorical', shuffle=False, \\n            batch_size=batch_size)\\n    X_transformed, y_labels = transform_X_with_PCA(image_generator, iPCA)\\n    \\n    # performing sanity check to make sure image names and image data are aligned by index\\n    data_transformed = {'image_names': image_generator.filenames, 'X_transformed': \\n                    X_transformed, 'y_labels': np.argmax(y_labels, axis=1)}\\n    print('All arrays have the same length: {}'.format(\\n            len(data_transformed['X_transformed']) == \\n                len(data_transformed['y_labels']) == \\n                len(data_transformed['image_names'])))\\n    class_labels = np.array([fname[0] for fname in data_transformed['image_names']])\\n    print('All image classes appear to match up: {}'.format(\\n            (data_transformed['y_labels'].astype('str') == class_labels).all()))\\n\\n    # save transformed vectors to disk\\n    with open(folder + '_transformed.pkl', 'wb') as f:\\n        pkl.dump(data_transformed, f)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import cPickle as pkl\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def transform_X_with_PCA(image_generator, iPCA): # generator must not be shuffled\n",
    "    X_transformed = []\n",
    "    y_labels = []\n",
    "    for i in xrange(image_generator.N // image_generator.batch_size + 1):\n",
    "        images, classes = image_generator.next()\n",
    "        X_transformed.append(iPCA.transform(images.reshape((len(images), -1))))\n",
    "        y_labels.append(classes)\n",
    "    X_transformed = np.concatenate(X_transformed)\n",
    "    y_labels = np.concatenate(y_labels)\n",
    "    # need to truncate if over sampled by 1 iteration\n",
    "    return X_transformed[:image_generator.N], y_labels[:image_generator.N]\n",
    "\n",
    "\n",
    "with open('iPCA.pkl', 'rb') as f:\n",
    "    iPCA = pkl.load(f)\n",
    "\n",
    "for folder in tqdm(['train', 'val', 'test']):\n",
    "    # transforming images to lower dimensionality\n",
    "    image_generator = image.ImageDataGenerator().flow_from_directory(new_path + folder, \n",
    "            target_size=(224, 224),class_mode='categorical', shuffle=False, \n",
    "            batch_size=batch_size)\n",
    "    X_transformed, y_labels = transform_X_with_PCA(image_generator, iPCA)\n",
    "    \n",
    "    # performing sanity check to make sure image names and image data are aligned by index\n",
    "    data_transformed = {'image_names': image_generator.filenames, 'X_transformed': \n",
    "                    X_transformed, 'y_labels': np.argmax(y_labels, axis=1)}\n",
    "    print('All arrays have the same length: {}'.format(\n",
    "            len(data_transformed['X_transformed']) == \n",
    "                len(data_transformed['y_labels']) == \n",
    "                len(data_transformed['image_names'])))\n",
    "    class_labels = np.array([fname[0] for fname in data_transformed['image_names']])\n",
    "    print('All image classes appear to match up: {}'.format(\n",
    "            (data_transformed['y_labels'].astype('str') == class_labels).all()))\n",
    "\n",
    "    # save transformed vectors to disk\n",
    "    with open(folder + '_transformed.pkl', 'wb') as f:\n",
    "        pkl.dump(data_transformed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "import cPickle as pkl\n",
    "\n",
    "\n",
    "with open('train_transformed.pkl', 'rb') as f:\n",
    "    train_transformed = pkl.load(f)\n",
    "with open('val_transformed.pkl', 'rb') as f:\n",
    "    val_transformed = pkl.load(f)\n",
    "with open('test_transformed.pkl', 'rb') as f:\n",
    "    test.transformed = pkl.load(f)\n",
    "\n",
    "# Grad Search over Random Forest Hyperparameters using Stratified K-Fold Cross Validation\n",
    "param_grid = {\"n_estimators\": [100, 300], 'max_depth': np.arange(0, 100, 20)}\n",
    "rf = RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=42)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=kfold, n_jobs=-1, scoring='roc_auc')\n",
    "grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "print \"Metrics on Training Set, which has classes BALANCED by oversampling\"\n",
    "print_metrics(y_train_balanced, grid_search.predict(X_train_balanced))\n",
    "\n",
    "print \"Metrics on Validation Set, which has UNBALANCED classes\"\n",
    "print_metrics(y_val, grid_search.predict(X_val))\n",
    "print confusion_matrix(y_val, grid_search.predict(X_val))\n",
    "plot_ROC(y_val, grid_search.predict_proba(X_val)[:, 1])\n",
    "\n",
    "\n",
    "\n",
    "# For reading confusion matrix, get a nice plot\n",
    "#  [[TN FP]\n",
    "#   [TN TP]]\n",
    "\n",
    "# get the feature importance\n",
    "# check which hyperparameters were the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# glorot initialization?\n",
    "# sigmoid vs relu\n",
    "# increase dense neurons or more filters\n",
    "# learning rate\n",
    "# want to overfit; ideally should be more accurate than 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3648/3696 [============================>.] - ETA: 0s - loss: 0.9257 - acc: 0.5400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.py:1462: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3712/3696 [==============================] - 205s - loss: 0.9215 - acc: 0.5412 - val_loss: 0.7204 - val_acc: 0.5621\n",
      "CPU times: user 3min 24s, sys: 15.7 s, total: 3min 40s\n",
      "Wall time: 3min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "LeNet = get_LeNet_model()\n",
    "LeNet.optimizer.lr = 0.1\n",
    "LeNet.fit_generator(train_batches, train_batches.N // 10, nb_epoch=1, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3712/3696 [==============================] - 190s - loss: 0.7125 - acc: 0.5348 - val_loss: 0.6930 - val_acc: 0.5621\n",
      "CPU times: user 3min 21s, sys: 14.5 s, total: 3min 35s\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "LeNet.optimizer.lr = 0.1\n",
    "LeNet.fit_generator(train_batches, train_batches.N // 10, nb_epoch=1, \n",
    "                    validation_data=val_batches, nb_val_samples=val_batches.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5806,  0.0008],\n",
       "       [ 0.4187,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008],\n",
       "       [ 0.4186,  0.5805,  0.0008]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LeNet.predict(train_batches.next()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {},
  "nbpresent": {
   "slides": {
    "28b43202-5690-4169-9aca-6b9dabfeb3ec": {
     "id": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "prev": null,
     "regions": {
      "3bba644a-cf4d-4a49-9fbd-e2554428cf9f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f3d3a388-7e2a-4151-9b50-c20498fceacc",
        "part": "whole"
       },
       "id": "3bba644a-cf4d-4a49-9fbd-e2554428cf9f"
      }
     }
    },
    "8104def2-4b68-44a0-8f1b-b03bf3b2a079": {
     "id": "8104def2-4b68-44a0-8f1b-b03bf3b2a079",
     "prev": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "regions": {
      "7dded777-1ddf-4100-99ae-25cf1c15b575": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fe47bd48-3414-4657-92e7-8b8d6cb0df00",
        "part": "whole"
       },
       "id": "7dded777-1ddf-4100-99ae-25cf1c15b575"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
